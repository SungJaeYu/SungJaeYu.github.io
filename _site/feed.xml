<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SungJae Yu's Blog</title>
    <description>For Study
</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 29 Jan 2021 02:36:28 +0900</pubDate>
    <lastBuildDate>Fri, 29 Jan 2021 02:36:28 +0900</lastBuildDate>
    <generator>Jekyll v3.8.6</generator>
    
      <item>
        <title>Transfer Learning</title>
        <description>&lt;p&gt;전이학습은 학습 데이터가 부족한 모델을 구축하기 위해 사용되는 방법이다.&lt;br /&gt;
예를 들어, 학습 데이터가 부족한 x-lay 이미지를 판단하는 모델을 만들려할 때&lt;br /&gt;
우리는 학습 데이터가 많은 일반 이미지 인식 모델의 layers를 가져와서&lt;br /&gt;
x-lay 이미지 모델에 사용할 수 있다.&lt;br /&gt;
이처럼 실제 학습 데이터가 부족한 모델을 구축할 때, 비슷한 형태의 데이터를 사용하는&lt;br /&gt;
다량의 데이터로 구축된 모델을 전이학습하여 성능을 높일 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/study/ML/Transferlearning.png&quot; alt=&quot;Transfer Learning&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/29/ML-transfer-learning.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/29/ML-transfer-learning.html</guid>
        
        <category>machinelearning</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>Multi-task Learning</title>
        <description>&lt;p&gt;Transfer learning(전이학습)은 빅 데이터의 모델 A를 적은 데이터 모델 B에 적용시키는 순차적인 방법이었다.&lt;br /&gt;
하지만 &lt;strong&gt;Multi-task Learning&lt;/strong&gt;은 모델 A와 모델 B를 동시에 학습시키는 방법이다.&lt;br /&gt;
예로 길거리의 이미지로&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;정지 신호가 있는지 판단하는 모델&lt;/li&gt;
  &lt;li&gt;보행자가 있는지 판단하는 모델&lt;/li&gt;
  &lt;li&gt;차가 있는지 판단하는 모델&lt;/li&gt;
  &lt;li&gt;신호등을 판단하는 모델&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;을 동시에 학습시키는 방법이다.&lt;br /&gt;
Input은 1개 이미지만 label은 4개가 존재하게 된다.&lt;br /&gt;
&lt;em&gt;Softmax regression과의 차이점은 Softmax는 하나의 label을 가지게 된다는 점이다.&lt;/em&gt;
&lt;img src=&quot;/assets/img/study/ML/multitask.png&quot; alt=&quot;Multi-task Learning&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Multi-task learning&lt;/strong&gt;은 세가지 상황에서 도움이 된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;저수준의 구조가 비슷할 때&lt;/li&gt;
  &lt;li&gt;각 task의 데이터 양이 비슷할 때&lt;/li&gt;
  &lt;li&gt;모든 task의 충분히 큰 신경망을 학습시킬 수 있을 때&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Rich Carona는 충분히 크지 않은 신경망을 multi-task learning 시키면 따로 학습시키는 것보다&lt;br /&gt;
성능이 저하된다는 사실을 알아냈다.&lt;br /&gt;
그러나 각 각 따로 학습시키는 것보다 데이터가 충분하고 신경망이 충분히 크면&lt;br /&gt;
multi-task learning이 도움이 된다는 건 확실하다.&lt;/p&gt;

&lt;p&gt;Transfer learning(전이학습)은 데이터가 적은 모델을 위한 방법이었다.&lt;br /&gt;
하지만 multi-task learning은 각 task 별 데이터가 필요하기 때문에 좀 더 특별한 상황에서 사용된다.&lt;br /&gt;
현재 전이학습이 더 많이 사용되고 있다. 하지만 두 방법 모두 도움이 되는 방법 임은 확실하다.&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/29/ML-multi-task-learning.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/29/ML-multi-task-learning.html</guid>
        
        <category>machinelearning</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>MAC, IP, ARP</title>
        <description>&lt;h2 id=&quot;mac-주소&quot;&gt;MAC 주소&lt;/h2&gt;
&lt;p&gt;MAC 주소(Media Access Control Address)는 네트워크 세그먼트의 &lt;strong&gt;데이터 링크 계층&lt;/strong&gt;에서&lt;br /&gt;
통신을 위한 네트워크 인터페이스에 할당된 교유 식별자이다.&lt;br /&gt;
MAC 주소는 이더넷과 와이파이를 포함한 대부분의 IEEE 802 네트워크 기술에 네트워크 주소로 사용된다.&lt;br /&gt;
MAC 주소는 하드웨어에 저장되어, 제조업체의 등록된 식별 번호로 인코딩되며 &lt;strong&gt;BIA(burned-in Address)&lt;/strong&gt;  로 부를수 있다.&lt;br /&gt;
&lt;strong&gt;이더넷 하드웨어 주소(Ethernet hardware address, EHA), 하드웨어 주소, 물리주소&lt;/strong&gt;로 부르기도 한다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;ip-주소&quot;&gt;IP 주소&lt;/h2&gt;
&lt;p&gt;IP 주소는 컴퓨터 네트워크에서 장치들이 서로를 인식하고 통신을 하기 위해서 사용하는 특수한 번호이다.&lt;br /&gt;
오늘날 주로 IPv4가 사용되고 있지만, 주소가 부족해지면서 IPv6가 사용되기 시작됐다.
IP는 255.255.255.255까지 가능하다.&lt;br /&gt;
127.0.0.1은 localhost IP로 자기자신을 가리킨다.&lt;/p&gt;

&lt;h3 id=&quot;ip-datagram&quot;&gt;IP Datagram&lt;/h3&gt;
&lt;p&gt;IP 계층의 패킷을 의미한다. Header+Data로 구성된다.
Header의 구성 요소는&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Version : IPv4(0100), IPv6(0110)&lt;/li&gt;
  &lt;li&gt;Header Length&lt;/li&gt;
  &lt;li&gt;서비스타입(Differentiated Services) : QoS 제공을 위해 사용&lt;/li&gt;
  &lt;li&gt;Total Length&lt;/li&gt;
  &lt;li&gt;식별자(Identification)&lt;/li&gt;
  &lt;li&gt;Flag&lt;/li&gt;
  &lt;li&gt;단편옵셋(Fragmentation Offset)&lt;/li&gt;
  &lt;li&gt;수명(TTL)&lt;/li&gt;
  &lt;li&gt;Protocol&lt;/li&gt;
  &lt;li&gt;Checksum&lt;/li&gt;
  &lt;li&gt;Source Address&lt;/li&gt;
  &lt;li&gt;Destination Address&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ip-class&quot;&gt;IP Class&lt;/h3&gt;
&lt;p&gt;IP 주소는 32bit로 구성 1바이트.1바이트.1바이트.1바이트 (255.255.255.255)&lt;br /&gt;
IP는 네트워크 영역과 호스트IP 영역이 구분되어있다.
클래스는 어디부터가 네트워크 영역인지 호스트IP 영역인지를 나타낸다.
&lt;img src=&quot;https://t1.daumcdn.net/cfile/tistory/99068D495BE8101D34&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;a-class&quot;&gt;A Class&lt;/h4&gt;
&lt;p&gt;A Class는 0으로 시작한다.&lt;br /&gt;
네트워크 주소 영역이 작기 때문에 많은 경우의 호스트 IP를 가질수 있다.&lt;br /&gt;
&lt;strong&gt;IP 범위는 0.0.0.0 ~ 127.255.255.255&lt;/strong&gt;까지 이다.&lt;br /&gt;
네트워크 주소는 &lt;strong&gt;2^7&lt;/strong&gt;&lt;br /&gt;
호스트 주소의 경우의 수는 &lt;strong&gt;(2^24)-2&lt;/strong&gt; 이다.&lt;br /&gt;
모두 1인경우와 모두 0인 경우는 각 각 브로트캐스트 주소, 네트워크 주소로 사용하기 때문에 제외한다.&lt;/p&gt;

&lt;h4 id=&quot;b-class&quot;&gt;B Class&lt;/h4&gt;
&lt;p&gt;B Class는 10으로 시작한다.
&lt;strong&gt;범위는 128.0.0.0 ~ 191.255.255.255&lt;/strong&gt;까지 이다.&lt;br /&gt;
네트워크 주소 경우의 수는 &lt;strong&gt;2^14&lt;/strong&gt;&lt;br /&gt;
호스트 주소 경우의 수는 &lt;strong&gt;(2^16)-2&lt;/strong&gt;이다.
-2는 A class와 같은 이유이다.&lt;/p&gt;

&lt;h4 id=&quot;c-class&quot;&gt;C Class&lt;/h4&gt;
&lt;p&gt;110으로 시작한다.
&lt;strong&gt;범위는 192.0.0.0 ~ 223.255.255.255&lt;/strong&gt;&lt;br /&gt;
네트워크 경우의 수 &lt;strong&gt;2^21&lt;/strong&gt;&lt;br /&gt;
호스트 주소 경우의 수 &lt;strong&gt;(2^8)-2&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;arp&quot;&gt;ARP&lt;/h2&gt;
&lt;p&gt;주소 결정 프로토콜(Address Resolution Protocol)은 네트워크 상에서 IP 주소를&lt;br /&gt;
물리적 네트워크 주소로 대응 시키기 위해 사용되는 프로토콜이다.&lt;br /&gt;
일종의 IP 주소와 MAC 주소를 대응 시켜놓은 table이다.&lt;/p&gt;

&lt;hr /&gt;
</description>
        <pubDate>Thu, 28 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/28/CS-mac-ip-arp.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/28/CS-mac-ip-arp.html</guid>
        
        <category>computerscience</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>Training and Testing on different distribution</title>
        <description>&lt;p&gt;Training을 시킬 때 우리는 많은 데이터셋을 필요로한다.&lt;br /&gt;
하지만 우리가 학습시킬 수 있는 데이터셋이 많지 않을 때 비슷한 환경의 데이터 셋을 가져와서 학습시킬 수 있다.&lt;br /&gt;
예를 들어, 핸드폰 이미지 인식을 할 때, 우리가 가지고 있는 데이터 셋이 10000개 뿐이라고 가정하자,&lt;br /&gt;
하지만 인터넷에 카메라로 찍은 사진 데이터는 20만개가 존재한다.&lt;br /&gt;
카메라로 찍은 사진 데이터와 핸드폰으로 찍은 사진 데이터는 서로 다르다. 하지만 핸드폰 이미지 인식을 학습시킬 때,&lt;br /&gt;
카메라로 찍은 데이터를 사용하여 정확도를 높일 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;데이터-구성&quot;&gt;데이터 구성&lt;/h2&gt;
&lt;p&gt;위 예에서 사용할 수 있는 데이터 구성은 이렇다.&lt;/p&gt;
&lt;h3 id=&quot;1-option-1&quot;&gt;1. Option 1&lt;/h3&gt;
&lt;p&gt;카메라 데이터와 핸드폰 데이터를 무작위로 섞은 뒤,&lt;br /&gt;
흔히 하는 대로 적절한 비율로 Train, Dev, Test로 분리한다.&lt;br /&gt;
하지만, 이렇게 할경우 Dev, Test Set이 우리가 원하는 환경과 다르게 된다.
우리의 목표는 핸드폰 이미지를 인식하는 것이다.&lt;br /&gt;
하지만 카메라 이미지를 Dev, Test Set에 놓는 것은 옳지 못한 결과를 낼 수 있다.&lt;br /&gt;
즉 이 방법은 옳지 못하다.&lt;/p&gt;

&lt;h3 id=&quot;2-option-2&quot;&gt;2. Option 2&lt;/h3&gt;
&lt;p&gt;우리가 원하는 결과를 얻기 위해 Dev, Test Set은 핸드폰 이미지로만 구성한다.
그리고 Train Set에만 카메라 이미지를 포함시킨다.
즉, Train Set을 20만개의 카메라 데이터 + 5000개의 핸드폰 데이터로 설정한다.&lt;br /&gt;
그리고 Dev, Test를 각 2500개로 설정한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;에러의-중의성&quot;&gt;에러의 중의성&lt;/h2&gt;
&lt;p&gt;Train error가 1%라고 할 때, Dev error가 8%라면 이는 Train에 과대적합 된것인가??&lt;br /&gt;
Different distribution data를 학습시켰기 때문에 이 error 차이는 두가지 의미를 가진다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Train에 과대적합, 즉 variance가 높음&lt;/li&gt;
  &lt;li&gt;Dev set과 Train set distribution의 난이도 차이(Data Mismatch)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;2번째 상황을 예로 들어보자, 우리는 카메라 이미지를 가지고 있다. 인터넷 카메라 이미지는 화질이 높고, 정확하게 찍혔다.&lt;br /&gt;
하지만 핸드폰 이미지는 화질이 낮고, 흐리며, 잘못 찍혔을 수 있다. 즉, 핸드폰 이미지 인식이 카메라 이미지 인식보다 어렵다.&lt;br /&gt;
그렇기 때문에 Dev set의 error가 높게 나올 수 있다.&lt;br /&gt;
이를 해결하기 위한 방법으로 &lt;strong&gt;Train Dev Set&lt;/strong&gt;을 사용할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;train-dev-set&quot;&gt;Train Dev Set&lt;/h3&gt;
&lt;p&gt;Train set에서 Train dev set을 따로 분리한다. 그러면 이제 Train set과 Train dev set은 같은 distribution을 가진다.&lt;br /&gt;
Train dev set의 error를 확인하면 이 error 차이가 &lt;strong&gt;variance&lt;/strong&gt; 때문인지 &lt;strong&gt;data mismatch&lt;/strong&gt;때문인지 알 수 있다.&lt;/p&gt;

&lt;p&gt;첫번째 예를 들어보면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Train Error : 1%&lt;/li&gt;
  &lt;li&gt;Train Dev Error : 8%&lt;/li&gt;
  &lt;li&gt;Dev Error : 9%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 경우는 Train dev error와 Train error의 차이가 크기 때문에 variance 때문임을 알 수 있다.&lt;/p&gt;

&lt;p&gt;두번째 경우는&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Train Error : 1%&lt;/li&gt;
  &lt;li&gt;Train Dev Error : 2%&lt;/li&gt;
  &lt;li&gt;Dev Error : 9%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서는 Dev Error가 큰 차이를 보이므로, Data Mismatch가 원인임을 알 수 있다.&lt;/p&gt;

&lt;hr /&gt;
</description>
        <pubDate>Sun, 24 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/24/ML-training-and-testing-on-different-distribution.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/24/ML-training-and-testing-on-different-distribution.html</guid>
        
        <category>machinelearning</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>Bayes Error</title>
        <description>&lt;h2 id=&quot;bayes-error&quot;&gt;Bayes Error&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Bayes error&lt;/strong&gt;는 모든 machine learning 모델의 &lt;strong&gt;최소 오차&lt;/strong&gt;이다.&lt;br /&gt;
즉, 모델의 error 참조점이 된다.&lt;br /&gt;
모델의 Bayes error 기준으로 train error와 test error를 비교하여,&lt;br /&gt;
모델의 bias를 줄여야 하는지 variance를 줄여야 하는 지 결정할 수 있다.&lt;br /&gt;
&lt;strong&gt;Bayes err&lt;/strong&gt;는 &lt;strong&gt;human level error&lt;/strong&gt;로 추정 할 수있지만,&lt;br /&gt;
요즘에는 인간의 능력치를 넘어서는 기계학습 분야와 모델이 존재하기 때문에&lt;br /&gt;
모델을 학습시키면서 추정해야 할 수도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Bayes err : 2%&lt;/li&gt;
  &lt;li&gt;train err : 3%&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;test err : 3.5%&lt;br /&gt;
이 경우에는 Bayes err와 train err의 차이가 1%인 반면에 train과 test err 차이가 0.5%이기 때문에 &lt;strong&gt;bias&lt;/strong&gt;를 줄이는 것을 목표로 해야된다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Bayes err : 2%&lt;/li&gt;
  &lt;li&gt;train err : 3%&lt;/li&gt;
  &lt;li&gt;test err : 5%&lt;br /&gt;
이 경우에는 Bayes err와 train err의 차이가 1%, train과 test err 차이가 2%이므로 &lt;strong&gt;variance&lt;/strong&gt;를 줄이기 위해 노력해야함을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 23 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/23/ML-bayeserror.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/23/ML-bayeserror.html</guid>
        
        <category>machinelearning</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>OSI Model</title>
        <description>&lt;h1 id=&quot;osi-model&quot;&gt;OSI Model&lt;/h1&gt;
&lt;p&gt;OSI(Open System Interconnection Reference Model)은 국제표준화기구(ISO)에서 개발한 모델로,&lt;br /&gt;
컴퓨터 네트워크 프로토콜 디자인과 통신을 계층으로 나누어 설명한 것이다. 일반적으로
&lt;strong&gt;OSI 7 Layer&lt;/strong&gt;라고 한다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;physical-layer&quot;&gt;Physical Layer&lt;/h2&gt;
&lt;p&gt;물리 계층은 네트워크의 기본 네트워크 하드웨어 전송 기술을 이룬다. &lt;br /&gt;
네트워크의 높은 수준의 논리 데이터 구조를 기초로 하는 필수 계층이다.&lt;br /&gt;
다양한 특징의 하드웨어 기술이 접목되어 있기에 OSI 아키텍처에서 가장 복잡한 계층으로 간주된다.&lt;br /&gt;
Switch 이전에 사용되던 &lt;strong&gt;Hub&lt;/strong&gt;와, &lt;strong&gt;Cabling&lt;/strong&gt; 등이 물리 계층이다.&lt;/p&gt;

&lt;h3 id=&quot;cable&quot;&gt;Cable&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Cable&lt;/strong&gt;은 두 종류로 나누어 진다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fiber&lt;/li&gt;
  &lt;li&gt;Copper&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Fiber&lt;/strong&gt;는 일명 광케이블로 빛을 전송하는 한개 혹은 여러개의 optical fibers(광섬유)로 구성된다.&lt;br /&gt;
Fiber optics는 전송속도가 빠르고 이동간 에너지 손실이 없기 때문에 원거리 통신에 사용가능하다.
또한 전파 간섭이 없기 때문에 간섭을 통한 신호 에러도 피할 수 있다. &lt;br /&gt;
하지만 광섬유를 통한 광신호를 전자 신호로 변화하여 사용해야 하며,&lt;br /&gt;
제조 물성이 한정적이며, 공정 다양성이 상대적으로 적고 제조가 까다롭다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Copper&lt;/strong&gt;은 Fiber cable의 단점이 장점이나,&lt;br /&gt;
Fiber의 가격이 내려감에 따라 Copper Cable의 사용도가 낮아졌다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;datalink-layer&quot;&gt;Datalink Layer&lt;/h2&gt;
&lt;p&gt;데이터 링크 계층은 포인트 투 포인트 간 신뢰성 있는 전송을 보장하기 위한 계층으로 CRC 기반의 오류 제어와 흐름제어가 필요하다. 네트워크 위의 개체들간 데이터를 전달하고, 물리 계층에서 발생할 수 있는 오류를 찾아 내고, 수정하는 데 필요한 기능적, 절차적 수단을 제공한다. 주소 값은 물리적으로 할당 받는 MAC 주소를 사용한다.&lt;br /&gt;
&lt;em&gt;MAC 주소는 네트워크 카드가 만들어질때 설정되는 고유한 물리 주소이다.&lt;/em&gt;&lt;br /&gt;
데이터 링크 계층의 예는 이더넷이다. 이 외에도 HDLC나 ADCCP 같은 포인트 투 포인트 프로토콜이나&lt;br /&gt;
패킷 스위칭 네트워크 LLC, ALOHA 같은 근거리 네트워크용 프로토콜이 있다.&lt;br /&gt;
네트워크 &lt;strong&gt;Bridge(브릿지)&lt;/strong&gt; 나 &lt;strong&gt;Switch(스위치)&lt;/strong&gt; 등이 이 계층에서 동작한다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;network-layer&quot;&gt;Network Layer&lt;/h2&gt;
&lt;p&gt;네트워크 계층은 여러 개의 노드를 거칠 때마다 경로를 찾아주는 역할을 하는 계층이다.
다양한 길이의 데이터를 네트워크를 통해 전달하고, 그 과정에서 전송 계층이 요구하는 서비스 품질(QoS)를&lt;br /&gt;
제공하기 위한 기능적, 절차적 수단을 제공한다.&lt;br /&gt;
네트워크 계층은&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Routing&lt;/li&gt;
  &lt;li&gt;흐름 제어&lt;/li&gt;
  &lt;li&gt;세그멘테이션(segmentation/desegmentation)&lt;/li&gt;
  &lt;li&gt;오류 제어&lt;/li&gt;
  &lt;li&gt;인터네트워킹(Internetworking)
등을 수행한다.
&lt;strong&gt;Router&lt;/strong&gt;가 이 계층에서 동작하고 이 계층에서 동작하는 &lt;strong&gt;Switch&lt;/strong&gt;도 있다.
&lt;strong&gt;IP(Internet Protocol)&lt;/strong&gt; 이 Network Layer 프로토콜이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;transport-layer&quot;&gt;Transport Layer&lt;/h2&gt;
&lt;p&gt;전송 계층은 양 끝단 사용자들이 신뢰성있는 데이터를 주고 받을 수 있도록 해주며,
상위 계층들이 데이터 전달의 유효성이나 효율성을 생각하지 않도록 해준다.&lt;br /&gt;
시퀀스 넘버 기반의 오류 제어 방식을 사용한다. 전송 계층은 특정 연결의 유효성을 제어하고,&lt;br /&gt;
일부 프로토콜은 상태 개념이 있고, 연결 기반이다. 이는 전송 계층이 패킷들의 전송이 유효한지 확인하고&lt;br /&gt;
전송 실패한 패킷들을 다시 전송한다는 것을 뜻한다.
&lt;strong&gt;TCP(Transmission Control Protocol)&lt;/strong&gt; 과 &lt;strong&gt;UDP(User Datagram Protocl)&lt;/strong&gt; 가 전송 계층의 프로토콜이다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;session-layer&quot;&gt;Session Layer&lt;/h2&gt;
&lt;p&gt;세션 계층은 양 끝단의 응용 프로세스가 통신을 관리하기 위한 방법을 제공한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Duplex&lt;/li&gt;
  &lt;li&gt;Half-duplex&lt;/li&gt;
  &lt;li&gt;Full-duplex
의 통신과 함께 체크 포인팅과 유휴, 종류, 다시 시작 과정 등을 수행한다.&lt;br /&gt;
이 계층은 TCP/IP 세션을 만들고 없애는 책임을 진다.
통신하는 사용자들을 동기화하고 오류복구 명령들을 일괄적으로 다룬다.&lt;/li&gt;
  &lt;li&gt;통신을 하기 위한 세션을 확립/유지/중단 (운영체제가 처리)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;presentation-layer&quot;&gt;Presentation Layer&lt;/h2&gt;
&lt;p&gt;표현 계층은 코드 간의 번역을 담당하여 사용자 시스템에서 데이터의 형식상 차이를 다루는 부담을&lt;br /&gt;
응용 계층으로 부터 덜어준다. MIME 인코딩이나 암호화 등의 동작이 표현 계층에서 이루어진다.&lt;br /&gt;
&lt;em&gt;예로 EBCDIC로 인코딩된 문서 파일을 ASCII로 인코딩된 파일로 바꾸어주는 것이 표현 계층의 역할이다&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;사용자의 명령어를 완성 및 결과 표현&lt;/li&gt;
  &lt;li&gt;포장/압축/암호화&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;application-layer&quot;&gt;Application Layer&lt;/h2&gt;
&lt;p&gt;응용 계층은 응용 프로세스와 직접 관계하여 일반적인 응용 서비스를 수행한다. 일반적인 응용 서비스는&lt;br /&gt;
관련된 응용 프로세스들 사이의 전환을 제공한다. 응용 서비스의 예로, 가성 터미널 등이 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;네트워크 소프트웨어 UI&lt;/li&gt;
  &lt;li&gt;사용자의 입출력&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
</description>
        <pubDate>Fri, 22 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/22/CS-osi.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/22/CS-osi.html</guid>
        
        <category>computerscience</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>Classification Evaluation Metrices</title>
        <description>&lt;h2 id=&quot;precision--recall&quot;&gt;Precision &amp;amp; Recall&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/study/ML/Precisionrecall.svg&quot; alt=&quot;Precision &amp;amp; Recall&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;precision&quot;&gt;Precision&lt;/h2&gt;

&lt;p&gt;머신러닝에서 분류 작업을 할 때, &lt;strong&gt;Precision&lt;/strong&gt;은 Positive로 분류된 element 중 실제 Positive element의 비율이다.&lt;br /&gt;
In a classification task, the &lt;strong&gt;Precision&lt;/strong&gt; for a class is the number of true positives&lt;br /&gt;
divided by the total number of elements labelled as belonging to the positive class&lt;br /&gt;
&lt;img src=&quot;/assets/img/study/ML/Precision.png&quot; alt=&quot;Precision&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;recall&quot;&gt;Recall&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Recall&lt;/strong&gt;은 실제 Positive class 중 positive로 올바르게 분류된 것의 비율이다.
&lt;strong&gt;Recall&lt;/strong&gt; is defined as the number of true positives&lt;br /&gt;
divided by the total number of elements that actually belong to the positive class&lt;br /&gt;
&lt;img src=&quot;/assets/img/study/ML/Recall.png&quot; alt=&quot;Recall&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;precision-recall-trade-off&quot;&gt;Precision-Recall Trade-off&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/study/ML/precision-recall-tradeoff.png&quot; alt=&quot;Precision-Recall Trade-off&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이상적인 시나리오는 &lt;strong&gt;Precision&lt;/strong&gt;과 &lt;strong&gt;Recall&lt;/strong&gt;이 둘 다 1.0인 경우이다.&lt;br /&gt;
하지만 대부분의 상황에서 이 두가지가 모두 만점을 받게 하긴 어렵다.&lt;br /&gt;
왜냐하면 대부분의 데이터셋에는 noise가 존재하기 때문에 완벽하게 분리하기란 어렵다.
따라서 모델은 Threshold를 사용하여 &lt;strong&gt;Precision&lt;/strong&gt;과 &lt;strong&gt;Recall&lt;/strong&gt;의 trade-off를 반영하여 선택되어야 한다.&lt;/p&gt;

&lt;h2 id=&quot;accuracy&quot;&gt;Accuracy&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Precision&lt;/strong&gt;과 &lt;strong&gt;Recall&lt;/strong&gt;은 Positive 상황만 고려한다. 하지만 False 상황 또한 고려할 수 있는 요소이다.&lt;br /&gt;
&lt;strong&gt;Accuracy&lt;/strong&gt;는 False 상황을 고려하여 계산된다. 이를 통해 False와 True가 모두 고려된 평가를 할 수 있다.
&lt;img src=&quot;/assets/img/study/ML/Accuracy.png&quot; alt=&quot;Accuracy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Accuracy&lt;/strong&gt;는 가장 직관적으로 모델의 성능을 나타내는 지표이다.&lt;br /&gt;
그러나, &lt;strong&gt;Bias of Domain&lt;/strong&gt;이 고려되어야 하므로 이를 보완하는 지표가 필요하다.&lt;br /&gt;
만약 입력 데이터가 불균형 데이터라면 &lt;strong&gt;Accuracy&lt;/strong&gt;는 올바른 평가를 내지 못한다.&lt;br /&gt;
즉, 데이터가 균형적일때 &lt;strong&gt;Accuracy&lt;/strong&gt;는 좋은 선택이 된다.&lt;/p&gt;

&lt;h2 id=&quot;f1-score&quot;&gt;F1 Score&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;F1 Score&lt;/strong&gt;는 &lt;strong&gt;Precision&lt;/strong&gt;과 &lt;strong&gt;Recall&lt;/strong&gt;의 harmonic mean(조화평균)이다.
&lt;img src=&quot;/assets/img/study/ML/F1score.png&quot; alt=&quot;F1-score&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;F1 Score&lt;/strong&gt;는 불균형 데이터에서도 준수한 성능 측정을 보여준다.
왜냐하면 사용되는 조화평균이 Precision과 Recall 사이의 불균형을 잘 보정해주기 때문이다.&lt;/p&gt;
</description>
        <pubDate>Wed, 20 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/20/ML-ClEvMet.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/20/ML-ClEvMet.html</guid>
        
        <category>machinelearning</category>
        
        
        <category>study</category>
        
      </item>
    
      <item>
        <title>Compiler, Linker, Builder</title>
        <description>&lt;h2 id=&quot;compiler&quot;&gt;Compiler&lt;/h2&gt;

&lt;p&gt;초기에 컴퓨터는 기계어로 프로그래밍 되었다. 하지만 기계어는 인간이 해석하기에 굉장히 어렵기때문에 새로운 방법이 필요했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기계어 집합을 표현하는 텍스트 문서를 만든다.&lt;/li&gt;
  &lt;li&gt;텍스트 문서를 기계어로 변환하는 프로그램을 만든다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 프로그램이 &lt;strong&gt;Compiler&lt;/strong&gt; 이고, 텍스트 문서는 &lt;strong&gt;Source Code File&lt;/strong&gt; 또는 &lt;strong&gt;Source File&lt;/strong&gt;이다.&lt;/p&gt;

&lt;h2 id=&quot;linker&quot;&gt;Linker&lt;/h2&gt;

&lt;p&gt;소스코드의 규모가 커지면서, 모든 소스코드를 한 파일안에 작성하는것은 불편하고 비효율적이었다.&lt;br /&gt;
따라서 한 소스 파일을 여러 소스 파일로 분리하는 방법이 창안되었다.&lt;br /&gt;
하지만 여러 소스 파일을 연결해야 하기때문에,
&lt;strong&gt;Linker&lt;/strong&gt;라는 프로그램이 만들어졌다.&lt;/p&gt;

&lt;h2 id=&quot;builder&quot;&gt;Builder&lt;/h2&gt;

&lt;p&gt;실행 파일을 만드는 절차는 아래와 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Write Source Code File&lt;/li&gt;
  &lt;li&gt;Compile Source Code&lt;/li&gt;
  &lt;li&gt;Link object files that Compiler made&lt;/li&gt;
  &lt;li&gt;Excutable File is created&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 절차를 &lt;strong&gt;Build&lt;/strong&gt;한다고 하고, 이 때 사용되는 프로그램을 &lt;strong&gt;Builder&lt;/strong&gt;라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Compile + Link = Build&lt;br /&gt;
Compiler + Linker = Builder&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 20 Jan 2021 00:00:00 +0900</pubDate>
        <link>http://localhost:4000/study/2021/01/20/CS-clb.html</link>
        <guid isPermaLink="true">http://localhost:4000/study/2021/01/20/CS-clb.html</guid>
        
        <category>computerscience</category>
        
        
        <category>study</category>
        
      </item>
    
  </channel>
</rss>
